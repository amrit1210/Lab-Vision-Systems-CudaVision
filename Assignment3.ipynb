{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Assignment3.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "metadata": {
        "id": "u6-l947Qn79O",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "66b7a343-ae84-4703-f7ad-1c044a99d576"
      },
      "cell_type": "code",
      "source": [
        "# http://pytorch.org/\n",
        "from os.path import exists\n",
        "from wheel.pep425tags import get_abbr_impl, get_impl_ver, get_abi_tag\n",
        "platform = '{}{}-{}'.format(get_abbr_impl(), get_impl_ver(), get_abi_tag())\n",
        "cuda_output = !ldconfig -p|grep cudart.so|sed -e 's/.*\\.\\([0-9]*\\)\\.\\([0-9]*\\)$/cu\\1\\2/'\n",
        "accelerator = cuda_output[0] if exists('/dev/nvidia0') else 'cpu'\n",
        "\n",
        "!pip install -q http://download.pytorch.org/whl/{accelerator}/torch-0.4.1-{platform}-linux_x86_64.whl torchvision\n",
        "import torch"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tcmalloc: large alloc 1073750016 bytes == 0x58f9a000 @  0x7f02300352a4 0x594e17 0x626104 0x51190a 0x4f5277 0x510c78 0x5119bd 0x4f5277 0x4f3338 0x510fb0 0x5119bd 0x4f5277 0x4f3338 0x510fb0 0x5119bd 0x4f5277 0x4f3338 0x510fb0 0x5119bd 0x4f6070 0x510c78 0x5119bd 0x4f5277 0x4f3338 0x510fb0 0x5119bd 0x4f6070 0x4f3338 0x510fb0 0x5119bd 0x4f6070\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "jfrwIs-Py-sh",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import torch"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "EmZ-0QPyzDOH",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "14086c33-a111-405d-8639-63b2c9a2dd98"
      },
      "cell_type": "code",
      "source": [
        "cuda = torch.cuda.is_available()\n",
        "print(cuda)"
      ],
      "execution_count": 235,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "True\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "dbQdKV5Gzb3c",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import torch.nn as nn\n",
        "import torchvision.transforms as transforms\n",
        "import torch.optim as optim\n",
        "import torchvision.datasets as dsets\n",
        "from torch.autograd import Variable\n",
        "import numpy as np\n",
        "import random as rand\n",
        "%matplotlib inline\n",
        "import matplotlib.pyplot as plt\n",
        "import torch.nn.functional as F\n",
        "from sklearn.metrics import confusion_matrix \n",
        "from sklearn.metrics import accuracy_score \n",
        "from sklearn.metrics import classification_report "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "OqAh_Ks5pkHI",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        },
        "outputId": "0a91581e-6c17-445b-8b35-fc6cdfd7405c"
      },
      "cell_type": "code",
      "source": [
        "torch.manual_seed(10)\n",
        "if cuda:\n",
        "  torch.cuda.manual_seed(10)\n",
        "'''\n",
        "LOADING DATASET\n",
        "\n",
        "'''\n",
        "\n",
        "trainset = dsets.CIFAR10('./data', train= True, download= True,transform = transforms.ToTensor())\n",
        "testset = dsets.CIFAR10('./data', train= False, download = True, transform = transforms.ToTensor())"
      ],
      "execution_count": 237,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "caUMnmSNqpuf",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "0bf0313e-1b41-4807-a6d4-b84a4db71802"
      },
      "cell_type": "code",
      "source": [
        "len(trainset), len(testset), trainset[0][0].size(), trainset[0][1]"
      ],
      "execution_count": 238,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(50000, 10000, torch.Size([3, 32, 32]), 6)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 238
        }
      ]
    },
    {
      "metadata": {
        "id": "3oTdn8Dn17EE",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "d65ed60a-30f0-492b-f30a-f9a9524d3cfa"
      },
      "cell_type": "code",
      "source": [
        "CLASSES = ('plane', 'car', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck')\n",
        "CLASSES[trainset[0][1]]"
      ],
      "execution_count": 239,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'frog'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 239
        }
      ]
    },
    {
      "metadata": {
        "id": "F_iv_owp18uF",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "batch_size = 100\n",
        "train_loader = torch.utils.data.DataLoader(dataset=trainset, batch_size=batch_size, shuffle =True, num_workers =2)\n",
        "test_loader=torch.utils.data.DataLoader(dataset=testset, batch_size=batch_size,shuffle=True,num_workers=2)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "OBfz3cwB2WWW",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "'''\n",
        "CREATE MODEL\n",
        "\n",
        "'''\n",
        "\n",
        "class Net(nn.Module):\n",
        "  def __init__(self):\n",
        "    super(Net,self).__init__()\n",
        "    self.input_hidden1 = nn.Linear(32*32*3,1000)\n",
        "    self.input_hidden1_dropout = nn.Dropout(0.2)\n",
        "    self.hidden1_hidden2 = nn.Linear(1000,700)\n",
        "    self.hidden1_hidden2_dropout = nn.Dropout(0.3)\n",
        "    self.hidden2_output = nn.Linear(700,10)\n",
        "    \n",
        "  def forward(self, x):\n",
        "    x= x.view(-1,32*32*3) #reshaping the input\n",
        "    x= F.relu(self.input_hidden1(x))\n",
        "    x= self.input_hidden1_dropout(x)\n",
        "    x= F.tanh(self.hidden1_hidden2(x))\n",
        "    x= self.hidden1_hidden2_dropout(x)\n",
        "    return self.hidden2_output(x)\n",
        "    "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "TXDM7Mrd3IPH",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "model = Net()\n",
        "if cuda:\n",
        "  model.cuda()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "dZZlSaFdKzhv",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "class CIFAR_MODEL:\n",
        "  def __init__(self, model, lr, optimizer_value, loss_type):\n",
        "    self.model = model\n",
        "    self.lr = lr\n",
        "    \n",
        "    weightdecay = 0\n",
        "    if loss_type == 'l2': #L2 regularization on loss by weightdecay\n",
        "      weightdecay=0.7\n",
        "      \n",
        "    optimizer = ''\n",
        "    if(optimizer_value == 'sgd'):\n",
        "      optimizer = optim.SGD(self.model.parameters(), lr= 0.01, momentum = 0.9, weight_decay=weightdecay)\n",
        "    elif(optimizer_value == 'adam'):\n",
        "      optimizer = optim.Adam(self.model.parameter(), lr= 0.01, weight_decay = weightdecay)\n",
        "    elif(optimizer_value == 'adagrad'):\n",
        "      optimizer = optim.Adagrad(self.model.parameters(), lr= 0.01, weight_decay = weightdecay )\n",
        "    elif(optimizer_value == 'adadelta'):\n",
        "      optimizer = optim.Adadelta(self.model.parameters(), lr= 0.01, weight_decay = weightdecay)\n",
        "    else:\n",
        "      optimizer = optim.RMSprop(self.model.parameters(), lr= 0.01, weight_decay = weightdecay)\n",
        "    \n",
        "  def train(self, epoch, loss_type, log_interval=100):\n",
        "    model.train()\n",
        "    for batch_idx, (data, target) in enumerate(train_loader):\n",
        "      if cuda:\n",
        "        data,target = data.cuda(), target.cuda()\n",
        "      data, target = Variable(data), Variable(target)\n",
        "      optimizer.zero_grad()\n",
        "      output = model(data)\n",
        "      loss = criterion(output, target)\n",
        "      if loss_type == 'l1': #L1 regularisation on loss\n",
        "        nn.L1Loss(loss)\n",
        "      loss.backward()\n",
        "      optimizer.step()\n",
        "      if batch_idx % log_interval == 0:\n",
        "            print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
        "                epoch, batch_idx * len(data), len(train_loader.dataset),\n",
        "                100. * batch_idx / len(train_loader), loss.data[0]))\n",
        "    \n",
        "  def test(self, loss_vector, accuracy_vector):\n",
        "    model.eval()\n",
        "    test_loss, correct = 0,0\n",
        "    for (data,target) in test_loader:\n",
        "      if cuda:\n",
        "        data, target = data.cuda(), target.cuda()\n",
        "      data, target = Variable(data, volatile = True), Variable(target)\n",
        "      output = model(data)\n",
        "      prediction = output.data.max(1)[1]\n",
        "      confusionmatrix = confusion_matrix(target,prediction)\n",
        "      test_loss+= criterion(output,target).data[0]\n",
        "      pred = output.data.max(1)[1]\n",
        "      correct+= pred.eq(target.data).cpu().sum()\n",
        "    \n",
        "    test_loss/=len(test_loader)\n",
        "    loss_vector.append(test_loss)\n",
        "    accuracy = 100.*correct/len(test_loader.dataset)\n",
        "    accuracy_vector.append(accuracy)\n",
        "    \n",
        "    print('Confusion_Matrix', confusionmatrix)\n",
        "    print('Accuracy Score :',accuracy_score(target, prediction))\n",
        "    print('\\nTest set: Average loss: {:.4f}, Accuracy: ({:.0f}%)\\n'.format(\n",
        "        test_loss, accuracy))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "d67tu1Pc3NBp",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "'''\n",
        "INSTANTIATE LOSS CLASS\n",
        "  \n",
        "'''\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "if cuda:\n",
        "  criterion = criterion.cuda()\n",
        "  \n",
        "def softmax(x):\n",
        "  x = x - np.max(x, axis=1).reshape((-1,1))\n",
        "  x = np.exp(x)\n",
        "  return x / np.sum(x, axis=1).reshape((-1, 1))\n",
        "  \n",
        "def hingeloss(x,y):\n",
        "  '''\n",
        "  We were trying to impleent it like this but we were facing some error\n",
        "  return (torch.clamp(torch.mm(y,x)-1,min = 0))\n",
        "  '''\n",
        "  return(max(0, 1-y*x))\n",
        "  \n",
        "def softmax_hingeloss(x,y):\n",
        "  return softmax(x) + hingeloss(x,y)\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "rUdblWNk3UP6",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1750
        },
        "outputId": "2b4e066c-7e82-474e-e8dc-a1701630eb56"
      },
      "cell_type": "code",
      "source": [
        "%%time\n",
        "epochs = 5\n",
        "lossv,accuv = [],[]\n",
        "learning_rate= 0.1\n",
        "loss_type = 'l2'\n",
        "cifar = CIFAR_MODEL(model, learning_rate, 'sgd', loss_type)\n",
        "for epoch in range(1, epochs+1):\n",
        "  cifar.train(epoch,loss_type)\n",
        "  cifar.test(lossv,accuv)"
      ],
      "execution_count": 248,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/torch/nn/functional.py:995: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
            "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:38: UserWarning: invalid index of a 0-dim tensor. This will be an error in PyTorch 0.5. Use tensor.item() to convert a 0-dim tensor to a Python number\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Train Epoch: 1 [0/50000 (0%)]\tLoss: 2.292908\n",
            "Train Epoch: 1 [10000/50000 (20%)]\tLoss: 2.308208\n",
            "Train Epoch: 1 [20000/50000 (40%)]\tLoss: 2.306726\n",
            "Train Epoch: 1 [30000/50000 (60%)]\tLoss: 2.328024\n",
            "Train Epoch: 1 [40000/50000 (80%)]\tLoss: 2.302966\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:46: UserWarning: volatile was removed and now has no effect. Use `with torch.no_grad():` instead.\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:50: UserWarning: invalid index of a 0-dim tensor. This will be an error in PyTorch 0.5. Use tensor.item() to convert a 0-dim tensor to a Python number\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Confusion_Matrix [[ 8  0  0  0  0  0  0  0  0  0]\n",
            " [11  0  0  0  0  0  0  0  0  0]\n",
            " [11  0  0  0  0  1  0  0  0  0]\n",
            " [ 6  0  0  0  0  1  0  0  0  0]\n",
            " [11  0  0  0  0  1  0  0  0  0]\n",
            " [ 8  0  0  0  0  1  0  0  0  0]\n",
            " [16  0  0  0  0  0  0  0  0  0]\n",
            " [ 9  0  0  0  0  0  0  0  0  0]\n",
            " [12  0  0  0  0  0  0  0  0  0]\n",
            " [ 4  0  0  0  0  0  0  0  0  0]]\n",
            "Accuracy Score : 0.09\n",
            "\n",
            "Test set: Average loss: 2.3027, Accuracy: (10%)\n",
            "\n",
            "Train Epoch: 2 [0/50000 (0%)]\tLoss: 2.314537\n",
            "Train Epoch: 2 [10000/50000 (20%)]\tLoss: 2.305744\n",
            "Train Epoch: 2 [20000/50000 (40%)]\tLoss: 2.292685\n",
            "Train Epoch: 2 [30000/50000 (60%)]\tLoss: 2.313194\n",
            "Train Epoch: 2 [40000/50000 (80%)]\tLoss: 2.300921\n",
            "Confusion_Matrix [[ 8  0  0  0  0  0  0  0  0  0]\n",
            " [10  0  0  0  0  0  0  0  0  0]\n",
            " [12  0  0  0  0  0  0  0  0  0]\n",
            " [12  0  0  0  0  0  0  0  0  0]\n",
            " [14  0  0  0  0  1  0  0  0  0]\n",
            " [ 6  0  0  0  0  0  0  0  0  0]\n",
            " [10  0  0  0  0  2  0  0  0  0]\n",
            " [11  0  0  0  0  1  0  0  0  0]\n",
            " [ 5  0  0  0  0  0  0  0  0  0]\n",
            " [ 8  0  0  0  0  0  0  0  0  0]]\n",
            "Accuracy Score : 0.08\n",
            "\n",
            "Test set: Average loss: 2.3027, Accuracy: (10%)\n",
            "\n",
            "Train Epoch: 3 [0/50000 (0%)]\tLoss: 2.294441\n",
            "Train Epoch: 3 [10000/50000 (20%)]\tLoss: 2.311917\n",
            "Train Epoch: 3 [20000/50000 (40%)]\tLoss: 2.290836\n",
            "Train Epoch: 3 [30000/50000 (60%)]\tLoss: 2.311456\n",
            "Train Epoch: 3 [40000/50000 (80%)]\tLoss: 2.315565\n",
            "Confusion_Matrix [[10  0  0  0  0  0  0  0  0  0]\n",
            " [ 7  0  0  0  0  1  0  0  0  0]\n",
            " [ 9  0  0  0  0  1  0  0  0  0]\n",
            " [15  0  0  0  0  2  0  0  0  0]\n",
            " [11  0  0  0  0  0  0  0  0  0]\n",
            " [ 6  0  0  0  0  1  0  0  0  0]\n",
            " [ 9  0  0  0  0  0  0  0  0  0]\n",
            " [ 7  0  0  0  0  1  0  0  0  0]\n",
            " [12  0  0  0  0  0  0  0  0  0]\n",
            " [ 8  0  0  0  0  0  0  0  0  0]]\n",
            "Accuracy Score : 0.11\n",
            "\n",
            "Test set: Average loss: 2.3027, Accuracy: (10%)\n",
            "\n",
            "Train Epoch: 4 [0/50000 (0%)]\tLoss: 2.327832\n",
            "Train Epoch: 4 [10000/50000 (20%)]\tLoss: 2.297014\n",
            "Train Epoch: 4 [20000/50000 (40%)]\tLoss: 2.324221\n",
            "Train Epoch: 4 [30000/50000 (60%)]\tLoss: 2.312448\n",
            "Train Epoch: 4 [40000/50000 (80%)]\tLoss: 2.296796\n",
            "Confusion_Matrix [[14  0  0  0  0  0  0  0  0  0]\n",
            " [ 6  0  0  0  0  1  0  0  0  0]\n",
            " [ 5  0  0  0  0  1  0  0  0  0]\n",
            " [ 8  0  0  0  0  0  0  0  0  0]\n",
            " [10  0  0  0  0  0  0  0  0  0]\n",
            " [12  0  0  0  0  0  0  0  0  0]\n",
            " [ 4  0  0  0  0  1  0  0  0  0]\n",
            " [12  0  0  0  0  0  0  0  0  0]\n",
            " [16  0  0  0  0  1  0  0  0  0]\n",
            " [ 8  0  0  0  0  1  0  0  0  0]]\n",
            "Accuracy Score : 0.14\n",
            "\n",
            "Test set: Average loss: 2.3027, Accuracy: (10%)\n",
            "\n",
            "Train Epoch: 5 [0/50000 (0%)]\tLoss: 2.312214\n",
            "Train Epoch: 5 [10000/50000 (20%)]\tLoss: 2.304504\n",
            "Train Epoch: 5 [20000/50000 (40%)]\tLoss: 2.321429\n",
            "Train Epoch: 5 [30000/50000 (60%)]\tLoss: 2.304922\n",
            "Train Epoch: 5 [40000/50000 (80%)]\tLoss: 2.304941\n",
            "Confusion_Matrix [[ 6  0  0  0  0  0  0  0  0  0]\n",
            " [ 7  0  0  0  0  1  0  0  0  0]\n",
            " [ 8  0  0  0  0  1  0  0  0  0]\n",
            " [10  0  0  0  0  1  0  0  0  0]\n",
            " [ 8  0  0  0  0  1  0  0  0  0]\n",
            " [ 9  0  0  0  0  0  0  0  0  0]\n",
            " [ 7  0  0  0  0  2  0  0  0  0]\n",
            " [13  0  0  0  0  1  0  0  0  0]\n",
            " [15  0  0  0  0  0  0  0  0  0]\n",
            " [ 9  0  0  0  0  1  0  0  0  0]]\n",
            "Accuracy Score : 0.06\n",
            "\n",
            "Test set: Average loss: 2.3027, Accuracy: (10%)\n",
            "\n",
            "CPU times: user 12.8 s, sys: 5.1 s, total: 17.9 s\n",
            "Wall time: 45 s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "kN16Cp_thcIz",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "torch.save(model.state_dict(), \"model_sgd.th\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "OCmMqBIIvSZl",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 134
        },
        "outputId": "5f859a73-1e2f-4ef2-ea8b-23ba04f066b1"
      },
      "cell_type": "code",
      "source": [
        "the_model = Net()\n",
        "the_model.load_state_dict(torch.load(\"model_sgd.th\"))\n",
        "print(the_model)\n"
      ],
      "execution_count": 250,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Net(\n",
            "  (input_hidden1): Linear(in_features=3072, out_features=1000, bias=True)\n",
            "  (input_hidden1_dropout): Dropout(p=0.2)\n",
            "  (hidden1_hidden2): Linear(in_features=1000, out_features=700, bias=True)\n",
            "  (hidden1_hidden2_dropout): Dropout(p=0.3)\n",
            "  (hidden2_output): Linear(in_features=700, out_features=10, bias=True)\n",
            ")\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "7f1R5CwhB3lK",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        },
        "outputId": "afb1b3ef-519d-4d5b-a0e7-baf55f78bca2"
      },
      "cell_type": "code",
      "source": [
        "torch.save(model, \"model_sgd.th.2\")"
      ],
      "execution_count": 251,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/torch/serialization.py:241: UserWarning: Couldn't retrieve source code for container of type Net. It won't be checked for correctness upon loading.\n",
            "  \"type \" + obj.__name__ + \". It won't be checked \"\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "id": "cPQb1w3EB6EC",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 134
        },
        "outputId": "a88cc719-91c8-4f10-94e6-c2c76363a342"
      },
      "cell_type": "code",
      "source": [
        "the_model2 = torch.load(\"model_sgd.th.2\")\n",
        "print(the_model2)"
      ],
      "execution_count": 252,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Net(\n",
            "  (input_hidden1): Linear(in_features=3072, out_features=1000, bias=True)\n",
            "  (input_hidden1_dropout): Dropout(p=0.2)\n",
            "  (hidden1_hidden2): Linear(in_features=1000, out_features=700, bias=True)\n",
            "  (hidden1_hidden2_dropout): Dropout(p=0.3)\n",
            "  (hidden2_output): Linear(in_features=700, out_features=10, bias=True)\n",
            ")\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "khkmCdbVC9Cm",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}