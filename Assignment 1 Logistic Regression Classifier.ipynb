{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, struct\n",
    "from array import array as pyarray\n",
    "from numpy import array, zeros\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "import numpy as np\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=DeprecationWarning) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_mnist(dataset=\"training\", digits=np.arange(10), path=\".\"):\n",
    "    #Loads MNIST files into 3D numpy arrays \n",
    "    if dataset == \"training\":\n",
    "        fname_img = os.path.join(path, 'train-images-idx3-ubyte')\n",
    "        fname_lbl = os.path.join(path, 'train-labels-idx1-ubyte')\n",
    "    elif dataset == \"testing\":\n",
    "        fname_img = os.path.join(path, 't10k-images-idx3-ubyte')\n",
    "        fname_lbl = os.path.join(path, 't10k-labels-idx1-ubyte')\n",
    "    else:\n",
    "        raise ValueError(\"dataset must be 'testing' or 'training'\")\n",
    "\n",
    "    flbl = open(fname_lbl, 'rb')\n",
    "    magic_nr, size = struct.unpack(\">II\", flbl.read(8))\n",
    "    lbl = pyarray(\"b\", flbl.read())\n",
    "    flbl.close()\n",
    "\n",
    "    fimg = open(fname_img, 'rb')\n",
    "    magic_nr, size, rows, cols = struct.unpack(\">IIII\", fimg.read(16))\n",
    "    img = pyarray(\"B\", fimg.read())\n",
    "    fimg.close()\n",
    "\n",
    "    ind = [ k for k in range(size) if lbl[k] in digits ]\n",
    "    N = len(ind)\n",
    "\n",
    "    images = zeros((N, rows, cols) )\n",
    "    labels = zeros((N ) )\n",
    "    for i in range(len(ind)):\n",
    "        images[i] = array(img[ ind[i]*rows*cols : (ind[i]+1)*rows*cols ]).reshape((rows, cols))\n",
    "        labels[i] = lbl[ind[i]]\n",
    "\n",
    "    return images, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x, train_y = load_mnist('training')\n",
    "test_x, test_y = load_mnist('testing')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((60000, 28, 28), (60000,), (10000, 28, 28), (10000,))"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# chekcing the dimension of dataset\n",
    "train_x.shape, train_y.shape, test_x.shape, test_y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((60000, 784), (10000, 784), (60000, 10), (10000, 10))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Reshaping the dataset\n",
    "x_train = np.reshape(train_x,(train_x.shape[0],-1))\n",
    "x_test = np.reshape(test_x,(test_x.shape[0],-1))\n",
    "ohe = OneHotEncoder(n_values=10)\n",
    "train_y = ohe.fit_transform(train_y.reshape(-1,1)).toarray()\n",
    "test_y = ohe.fit_transform(test_y.reshape(-1,1)).toarray()\n",
    "\n",
    "#normalising the dataset\n",
    "x_train = x_train/255\n",
    "x_test = x_test/255\n",
    "x_train.shape, x_test.shape, train_y.shape, test_y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 0.01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Bias variables with zero\n",
    "bias = np.zeros(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#softmax function for activation\n",
    "def softmax(z):\n",
    "    predict_y = []\n",
    "    predict = []\n",
    "    for i in z:\n",
    "        shifti = i-np.max(i)\n",
    "        exps = np.exp(shifti)/np.sum(np.exp(shifti))\n",
    "        predict_y.append(np.argmax(exps))\n",
    "        predict.append(exps)\n",
    "    return predict,predict_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#softmax derivative for gradient\n",
    "def softmax_gradient(s):\n",
    "    s = np.array(s)\n",
    "    s_gradient = s.reshape(-1,1)\n",
    "    return np.diagflat(s_gradient) - np.dot(s_gradient,s_gradient.T)        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#mean squared error\n",
    "def mse(batch_y,predict_y):\n",
    "    predict_y = np.array(predict_y)\n",
    "    predict_y = ohe.fit_transform(predict_y.reshape(-1,1)).toarray()\n",
    "    return batch_y - predict_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model for training\n",
    "def model(batch_x, batch_y,weight):\n",
    "    predict, predict_y = softmax(np.dot(batch_x,weight)+bias)\n",
    "    s_derivative = softmax_gradient(predict)\n",
    "    loss = mse(batch_y,predict_y)\n",
    "    gradient = np.dot(batch_x.T,loss)\n",
    "    del_w = learning_rate*gradient\n",
    "    #update weights\n",
    "    weight = weight + del_w  \n",
    "    return weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#random normal initialisation for weights\n",
    "#seed random no. for reproducibility\n",
    "np.random.seed(1)\n",
    "weight = np.random.rand(x_train.shape[1],10)\n",
    "weight.shape\n",
    "#training the model in batch of 20\n",
    "batchsize = 20\n",
    "for i in range(100): #100epochs\n",
    "    for j in range(len(x_train)-20):\n",
    "        batch_x = x_train[j:j+20]\n",
    "        batch_y = train_y[j:j+20]\n",
    "        model(batch_x,batch_y,weight)\n",
    "        j=j+20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.81272\n"
     ]
    }
   ],
   "source": [
    "#predict the output on test dataset\n",
    "#print(weight)\n",
    "predict_test, predict_testy = softmax(np.dot(x_test,weight)+bias)\n",
    "predict_testy = np.array(predict_testy)\n",
    "predict_testy = ohe.fit_transform(predict_testy.reshape(-1,1)).toarray()\n",
    "correct_prediction = np.equal(test_y, predict_testy)\n",
    "unique,count = np.unique(correct_prediction,return_counts = True)\n",
    "accuracy = (np.asscalar(count[np.argwhere(unique == True)])/np.sum(count))\n",
    "print(accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1rc1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
